{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StatefulSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to run both single-instance and replicated stateless pods, and even stateful pods utilizing persistent storage. You can run several replicated web-server pod instances and you can run a single database pod instance that uses persistent storage, provided either through plain pod volumes or through Persistent-Volumes bound by a PersistentVolumeClaim. But can you employ a ReplicaSet to replicate the database pod?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating stateful pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReplicaSets create multiple pod replicas from a single pod template. These replicas don’t differ from each other, apart from their name and IP address. If the pod template includes a volume, which refers to a specific PersistentVolumeClaim, all replicas of the ReplicaSet will use the exact same PersistentVolumeClaim and therefore the same PersistentVolume bound by the claim (shown in figure 10.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"https://dpzbhybb2pdcj.cloudfront.net/luksa/Figures/10fig01_alt.jpg\" data-action=\"zoom\" data-zoom-src=\"https://dpzbhybb2pdcj.cloudfront.net/luksa/HighResolutionFigures/figure_10-1.png\" class=\"medium-zoom-image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the reference to the claim is in the pod template, which is used to stamp out multiple pod replicas, you can’t make each replica use its own separate Persistent-VolumeClaim. You can’t use a ReplicaSet to run a distributed data store, where each instance needs its own separate storage—at least not by using a single ReplicaSet. To be honest, none of the API objects you’ve seen so far make running such a data store possible. You need something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS: STATEFUL CONTAINERS USING STATEFULSETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.eksworkshop.com/beginner/170_statefulset/statefulset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatefulSet manages the deployment and scaling of a set of Pods, and provides guarantees about the ordering and uniqueness of these Pods, suitable for applications that require one or more of the following. \n",
    "* Stable, unique network identifiers \n",
    "* Stable, persistent storage \n",
    "* Ordered, graceful deployment and scaling \n",
    "* Ordered, automated rolling updates\n",
    "\n",
    "In this Chapter, we will review how to deploy MySQL database using StatefulSet and Amazon Elastic Block Store (EBS) as PersistentVolume. The example is a MySQL single leader topology with multiple followers running asynchronous replication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ConfigMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands to download the ConfigMap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mysql-configmap.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: mysql-config\n",
    "  labels:\n",
    "    app: mysql\n",
    "data:\n",
    "  master.cnf: |\n",
    "    # Apply this config only on the leader.\n",
    "    [mysqld]\n",
    "    log-bin\n",
    "  slave.cnf: |\n",
    "    # Apply this config only on followers.\n",
    "    [mysqld]\n",
    "    super-read-only\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ConfigMap stores master.cnf, slave.cnf and passes them when initializing leader and follower pods defined in StatefulSet: * master.cnf is for the MySQL leader pod which has binary log option (log-bin) to provides a record of the data changes to be sent to follower servers. * slave.cnf is for follower pods which have super-read-only option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create “mysql-config” ConfigMap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl apply -f mysql-configmap.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes Service defines a logical set of Pods and a policy by which to access them. Service can be exposed in different ways by specifying a type in the serviceSpec. StatefulSet currently requires a Headless Service to control the domain of its Pods, directly reach each Pod with stable DNS entries. By specifying “None” for the clusterIP, you can create Headless Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mysql-services.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "# Headless service for stable DNS entries of StatefulSet members.\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: mysql\n",
    "  labels:\n",
    "    app: mysql\n",
    "spec:\n",
    "  ports:\n",
    "  - name: mysql\n",
    "    port: 3306\n",
    "  clusterIP: None\n",
    "  selector:\n",
    "    app: mysql\n",
    "---\n",
    "# Client service for connecting to any MySQL instance for reads.\n",
    "# For writes, you must instead connect to the leader: mysql-0.mysql.\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: mysql-read\n",
    "  labels:\n",
    "    app: mysql\n",
    "spec:\n",
    "  ports:\n",
    "  - name: mysql\n",
    "    port: 3306\n",
    "  selector:\n",
    "    app: mysql\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the mysql service is for DNS resolution so that when pods are placed by StatefulSet controller, pods can be resolved using pod-name.mysql. mysql-read is a client service that does load balancing for all followers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl apply -f mysql-services.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create StatefulSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StatefulSet consists of serviceName, replicas, template and volumeClaimTemplates: \n",
    "* serviceName is “mysql”, headless service we created in previous section \n",
    "* replicas is 3, the desired number of pod \n",
    "* template is the configuration of pod \n",
    "* volumeClaimTemplates is to claim volume for pod based on storageClassName, mysql-gp2 that we created in the Define Storageclass section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mysql-statefulset.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: mysql\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: mysql\n",
    "  serviceName: mysql\n",
    "  replicas: 3\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: mysql\n",
    "    spec:\n",
    "      initContainers:\n",
    "      - name: init-mysql\n",
    "        image: mysql:5.7\n",
    "        command:\n",
    "        - bash\n",
    "        - \"-c\"\n",
    "        - |\n",
    "          set -ex\n",
    "          # Generate mysql server-id from pod ordinal index.\n",
    "          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1\n",
    "          ordinal=${BASH_REMATCH[1]}\n",
    "          echo [mysqld] > /mnt/conf.d/server-id.cnf\n",
    "          # Add an offset to avoid reserved server-id=0 value.\n",
    "          echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf\n",
    "          # Copy appropriate conf.d files from config-map to emptyDir.\n",
    "          if [[ $ordinal -eq 0 ]]; then\n",
    "            cp /mnt/config-map/master.cnf /mnt/conf.d/\n",
    "          else\n",
    "            cp /mnt/config-map/slave.cnf /mnt/conf.d/\n",
    "          fi\n",
    "        volumeMounts:\n",
    "        - name: conf\n",
    "          mountPath: /mnt/conf.d\n",
    "        - name: config-map\n",
    "          mountPath: /mnt/config-map\n",
    "      - name: clone-mysql\n",
    "        image: gcr.io/google-samples/xtrabackup:1.0\n",
    "        command:\n",
    "        - bash\n",
    "        - \"-c\"\n",
    "        - |\n",
    "          set -ex\n",
    "          # Skip the clone if data already exists.\n",
    "          [[ -d /var/lib/mysql/mysql ]] && exit 0\n",
    "          # Skip the clone on leader (ordinal index 0).\n",
    "          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1\n",
    "          ordinal=${BASH_REMATCH[1]}\n",
    "          [[ $ordinal -eq 0 ]] && exit 0\n",
    "          # Clone data from previous peer.\n",
    "          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql\n",
    "          # Prepare the backup.\n",
    "          xtrabackup --prepare --target-dir=/var/lib/mysql\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /var/lib/mysql\n",
    "          subPath: mysql\n",
    "        - name: conf\n",
    "          mountPath: /etc/mysql/conf.d\n",
    "      containers:\n",
    "      - name: mysql\n",
    "        image: mysql:5.7\n",
    "        env:\n",
    "        - name: MYSQL_ALLOW_EMPTY_PASSWORD\n",
    "          value: \"1\"\n",
    "        ports:\n",
    "        - name: mysql\n",
    "          containerPort: 3306\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /var/lib/mysql\n",
    "          subPath: mysql\n",
    "        - name: conf\n",
    "          mountPath: /etc/mysql/conf.d\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: 500m\n",
    "            memory: 1Gi\n",
    "        livenessProbe:\n",
    "          exec:\n",
    "            command: [\"mysqladmin\", \"ping\"]\n",
    "          initialDelaySeconds: 30\n",
    "          periodSeconds: 10\n",
    "          timeoutSeconds: 5\n",
    "        readinessProbe:\n",
    "          exec:\n",
    "            # Check we can execute queries over TCP (skip-networking is off).\n",
    "            command: [\"mysql\", \"-h\", \"127.0.0.1\", \"-e\", \"SELECT 1\"]\n",
    "          initialDelaySeconds: 5\n",
    "          periodSeconds: 2\n",
    "          timeoutSeconds: 1\n",
    "      - name: xtrabackup\n",
    "        image: gcr.io/google-samples/xtrabackup:1.0\n",
    "        ports:\n",
    "        - name: xtrabackup\n",
    "          containerPort: 3307\n",
    "        command:\n",
    "        - bash\n",
    "        - \"-c\"\n",
    "        - |\n",
    "          set -ex\n",
    "          cd /var/lib/mysql\n",
    "\n",
    "          # Determine binlog position of cloned data, if any.\n",
    "          if [[ -f xtrabackup_slave_info ]]; then\n",
    "            # XtraBackup already generated a partial \"CHANGE MASTER TO\" query\n",
    "            # because we're cloning from an existing follower.\n",
    "            mv xtrabackup_slave_info change_master_to.sql.in\n",
    "            # Ignore xtrabackup_binlog_info in this case (it's useless).\n",
    "            rm -f xtrabackup_binlog_info\n",
    "          elif [[ -f xtrabackup_binlog_info ]]; then\n",
    "            # We're cloning directly from leader. Parse binlog position.\n",
    "            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1\n",
    "            rm xtrabackup_binlog_info\n",
    "            echo \"CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\\\n",
    "                  MASTER_LOG_POS=${BASH_REMATCH[2]}\" > change_master_to.sql.in\n",
    "          fi\n",
    "\n",
    "          # Check if we need to complete a clone by starting replication.\n",
    "          if [[ -f change_master_to.sql.in ]]; then\n",
    "            echo \"Waiting for mysqld to be ready (accepting connections)\"\n",
    "            until mysql -h 127.0.0.1 -e \"SELECT 1\"; do sleep 1; done\n",
    "\n",
    "            echo \"Initializing replication from clone position\"\n",
    "            # In case of container restart, attempt this at-most-once.\n",
    "            mv change_master_to.sql.in change_master_to.sql.orig\n",
    "            mysql -h 127.0.0.1 <<EOF\n",
    "          $(<change_master_to.sql.orig),\n",
    "            MASTER_HOST='mysql-0.mysql',\n",
    "            MASTER_USER='root',\n",
    "            MASTER_PASSWORD='',\n",
    "            MASTER_CONNECT_RETRY=10;\n",
    "          START SLAVE;\n",
    "          EOF\n",
    "          fi\n",
    "\n",
    "          # Start a server to send backups when requested by peers.\n",
    "          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \\\n",
    "            \"xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root\"\n",
    "        volumeMounts:\n",
    "        - name: data\n",
    "          mountPath: /var/lib/mysql\n",
    "          subPath: mysql\n",
    "        - name: conf\n",
    "          mountPath: /etc/mysql/conf.d\n",
    "        resources:\n",
    "          requests:\n",
    "            cpu: 100m\n",
    "            memory: 100Mi\n",
    "      volumes:\n",
    "      - name: conf\n",
    "        emptyDir: {}\n",
    "      - name: config-map\n",
    "        configMap:\n",
    "          name: mysql-config   \n",
    "  volumeClaimTemplates:\n",
    "  - metadata:\n",
    "      name: data\n",
    "    spec:\n",
    "      accessModes: [\"ReadWriteOnce\"]\n",
    "      storageClassName: mysql-gp2\n",
    "      resources:\n",
    "        requests:\n",
    "          storage: 10Gi\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
