{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pods: running containers in Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://kubernetes.io/docs/concepts/workloads/pods/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pod is the basic execution unit of a Kubernetes application–the smallest and simplest unit in the Kubernetes object model that you create or deploy. A Pod represents processes running on your Cluster.\n",
    "\n",
    "A Pod encapsulates an application’s container (or, in some cases, multiple containers), storage resources, a unique network IP, and options that govern how the container(s) should run. A Pod represents a unit of deployment: a single instance of an application in Kubernetes, which might consist of either a single container or a small number of containers that are tightly coupled and that share resources.\n",
    "\n",
    "Docker is the most common container runtime used in a Kubernetes Pod, but Pods support other container runtimes as well.\n",
    "\n",
    "Pods in a Kubernetes cluster can be used in two main ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li><strong>Pods that run a single container</strong>. The “one-container-per-Pod” model is the most common Kubernetes use case; in this case, you can think of a Pod as a wrapper around a single container, and Kubernetes manages the Pods rather than the containers directly.</li><li><p><strong>Pods that run multiple containers that need to work together</strong>. A Pod might encapsulate an application composed of multiple co-located containers that are tightly coupled and need to share resources. These co-located containers might form a single cohesive unit of service–one container serving files from a shared volume to the public, while a separate “sidecar” container refreshes or updates those files. The Pod wraps these containers and storage resources together as a single manageable entity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’ll\n",
    "start **reviewing all types of Kubernetes objects (or resources)** in greater detail, so\n",
    "you’ll understand when, how, and why to use each of them. We’ll start with pods,\n",
    "because they’re the central, most important, concept in Kubernetes. Everything\n",
    "else either manages, exposes, or is used by pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Centralni, najpomembnejši koncept v Kubernetesu\n",
    "- Vse ostalo upravlja, izpostavlja oziroma uporablja stroke\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve already learned that a pod is a **co-located group of containers** and represents\n",
    "the basic building block in Kubernetes. **Instead of deploying containers individually,\n",
    "you always deploy and operate on a pod of containers**. We’re not implying that a pod\n",
    "always includes more than one container—it’s common for pods to contain only a single\n",
    "container. The key thing about pods is that when a pod does contain multiple containers,\n",
    "**all of them are always run on a single worker node** — it never spans multiple\n",
    "worker nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **UNDERSTANDING WHY MULTIPLE CONTAINERS ARE BETTER THAN ONE CONTAINER RUNNING MULTIPLE PROCESSES**  Imagine an app consisting of multiple processes that either communicate through\n",
    "IPC (Inter-Process Communication) or through locally stored files, which requires\n",
    "them to run on the same machine. Because in Kubernetes you always run processes in\n",
    "containers and each container is much like an isolated machine, you may think it\n",
    "makes sense to run multiple processes in a single container, but you shouldn’t do that.\n",
    "**Containers are designed to run only a single process per container** (unless the\n",
    "process itself spawns child processes). If you run multiple unrelated processes in a\n",
    "single container, **it is your responsibility to keep all those processes running, manage\n",
    "their logs, and so on**. For example, you’d have to include a mechanism for automatically\n",
    "restarting individual processes if they crash. Also, all those processes would\n",
    "log to the same standard output, so you’d have a hard time figuring out what process\n",
    "logged what. Therefore, you need to run each process in its own container. That’s how Docker\n",
    "and Kubernetes are meant to be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another indication that containers should only run a single process is the fact that the container runtime only restarts the container when the container’s root process dies. It doesn’t care about any child processes created by this root process. If it spawns child processes, it alone is responsible for keeping all these processes running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because you’re not supposed to group multiple processes into a single container, it’s\n",
    "obvious you need another higher-level construct that will allow you to bind containers\n",
    "together and manage them as a single unit. This is the reasoning behind pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pod of containers allows you to run closely related processes together and provide\n",
    "them with (almost) the same environment as if they were all running in a single\n",
    "container, while keeping them somewhat isolated. This way, you get the best of both\n",
    "worlds. You can take advantage of all the features containers provide, while at the\n",
    "same time giving the processes the illusion of running together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all containers of a pod run under the same Network and UTS namespaces\n",
    "(we’re talking about Linux namespaces here), they all share the same hostname and\n",
    "network interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, all containers of a pod run under the same IPC namespace\n",
    "and can communicate through IPC. In the latest Kubernetes and Docker versions, they\n",
    "can also share the same PID namespace, but that feature isn’t enabled by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when it comes to the filesystem, things are a little different. Because most of the\n",
    "**container’s filesystem comes from the container image, by default, the filesystem of\n",
    "each container is fully isolated from other containers**. However, it’s possible to have\n",
    "them share file directories using a Kubernetes concept called a Volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One thing to stress here is that because containers in a pod run in the same Network\n",
    "namespace, they share the same IP address and port space. This means processes running\n",
    "in containers of the same pod need to take care not to bind to the same port\n",
    "numbers or they’ll run into port conflicts. But this only concerns containers in the\n",
    "same pod. Containers of different pods can never run into port conflicts, because\n",
    "each pod has a separate port space. \n",
    "\n",
    "- All the containers in a pod also have the same\n",
    "loopback network interface, so a container can communicate with other containers in\n",
    "the same pod through localhost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTRODUCING THE FLAT INTER-POD NETWORK**\n",
    " \n",
    "All pods in a Kubernetes cluster reside in a single flat, shared, network-address space\n",
    "(shown in figure 3.2), which means every pod can access every other pod at the other\n",
    "pod’s IP address. No NAT (Network Address Translation) gateways exist between them.\n",
    "When two pods send network packets between each other, they’ll each see the actual\n",
    "IP address of the other as the source IP in the packet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consequently, communication between pods is always simple. It doesn’t matter if two\n",
    "pods are scheduled onto a single or onto different worker nodes; in both cases the\n",
    "containers inside those pods can communicate with each other across the flat NATless\n",
    "network, much like computers on a local area network (LAN), regardless of the\n",
    "actual inter-node network topology. Like a computer on a LAN, each pod gets its own\n",
    "IP address and is accessible from all other pods through this network established specifically\n",
    "for pods. This is usually achieved through an additional software-defined network\n",
    "layered on top of the actual network.\n",
    "\n",
    "To sum up what’s been covered in this section: pods are logical hosts and behave\n",
    "much like physical hosts or VMs in the non-container world. **Processes running in the\n",
    "same pod are like processes running on the same physical or virtual machine, except\n",
    "that each process is encapsulated in a container.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing containers across pods properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should think of pods as separate machines, but where each one hosts only a certain\n",
    "app. Unlike the old days, when we used to cram all sorts of apps onto the same\n",
    "host, we don’t do that with pods. Because pods are relatively lightweight, you can have\n",
    "as many as you need without incurring almost any overhead. **Instead of stuffing everything\n",
    "into a single pod, you should organize apps into multiple pods, where each one\n",
    "contains only tightly related components or processes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Although nothing is stopping you from running both the frontend server and the\n",
    "database in a single pod with two containers, it isn’t the most appropriate way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLITTING MULTI-TIER APPS INTO MULTIPLE PODS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If both the frontend and backend are in the same pod, then both will always be\n",
    "run on the same machine.\n",
    "    - If you have a two-node Kubernetes cluster and only this single\n",
    "pod, you’ll only be using a single worker node and not taking advantage of the\n",
    "computational resources (CPU and memory) you have at your disposal on the second\n",
    "node.\n",
    "    - Splitting the pod into two would allow Kubernetes to schedule the frontend to\n",
    "one node and the backend to the other node, thereby improving the utilization of\n",
    "your infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLITTING INTO MULTIPLE PODS TO ENABLE INDIVIDUAL SCALING**:\n",
    "Another reason why you shouldn’t put them both into a single pod is scaling. A pod is\n",
    "also the basic unit of scaling. Kubernetes can’t horizontally scale individual containers;\n",
    "instead, it scales whole pods. If your pod consists of a frontend and a backend container,\n",
    "when you scale up the number of instances of the pod to, let’s say, two, you end\n",
    "up with two frontend containers and two backend containers.\n",
    "Usually, frontend components have completely different scaling requirements\n",
    "than the backends, so we tend to scale them individually. Not to mention the fact that\n",
    "backends such as databases are usually much harder to scale compared to (stateless)\n",
    "frontend web servers. If you need to scale a container individually, this is a clear indication\n",
    "that it needs to be deployed in a separate pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNDERSTANDING WHEN TO USE MULTIPLE CONTAINERS IN A POD**: The main reason to put multiple containers into a single pod is when the application\n",
    "consists of one main process and one or more complementary processes, as shown in\n",
    "figure 3.3.  For example, the main container in a pod could be a web server that serves files from\n",
    "a certain file directory, while an additional container (a sidecar container) periodically\n",
    "downloads content from an external source and stores it in the web server’s\n",
    "directory. In chapter 6 you’ll see that you need to use a Kubernetes Volume that you\n",
    "mount into both containers.\n",
    "\n",
    "Other examples of sidecar containers include log rotators and collectors, data processors,\n",
    "communication adapters, and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DECIDING WHEN TO USE MULTIPLE CONTAINERS IN A POD**\n",
    "\n",
    "To recap how containers should be grouped into pods—when deciding whether to\n",
    "put two containers into a single pod or into two separate pods, you always need to ask\n",
    "yourself the following questions:\n",
    "- Do they need to be run together or can they run on different hosts?\n",
    "- Do they represent a single whole or are they independent components?\n",
    "- Must they be scaled together or individually?\n",
    "\n",
    "Basically, you should always gravitate toward running containers in separate pods,\n",
    "unless a specific reason requires them to be part of the same pod. Figure 3.4 will help\n",
    "you memorize this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pods from YAML or JSON descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple YAML descriptor for a pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to create a file called `ex01-kubia-manual.yaml`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: kubia-manual\n",
    "spec:\n",
    "  containers:\n",
    "  - image: luksa/kubia\n",
    "    name: kubia\n",
    "    ports:\n",
    "    - containerPort: 8080\n",
    "      protocol: TCP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It conforms to the v1 version of the Kubernetes API. The\n",
    "type of resource you’re describing is a pod, with the name kubia-manual. The pod\n",
    "consists of a single container based on the luksa/kubia image. You’ve also given a\n",
    "name to the container and indicated that it’s listening on port 8080."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **SPECIFYING CONTAINER PORTS**: Specifying ports in the pod definition is purely informational. Omitting them has no\n",
    "effect on whether clients can connect to the pod through the port or not. If the container is accepting connections \n",
    "through a port bound to the 0.0.0.0 address, other\n",
    "pods can always connect to it, even if the port isn’t listed in the pod spec explicitly. But\n",
    "it makes sense to define the ports explicitly so that everyone using your cluster can\n",
    "quickly see what ports each pod exposes. Explicitly defining ports also allows you to\n",
    "assign a name to each port, which can come in handy, as you’ll see later in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using kubectl create to create the pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the pod from your YAML file, use the kubectl create command:\n",
    "    \n",
    "    $ kubectl create -f kubia-manual.yaml\n",
    "    \n",
    "The kubectl create -f command is used for creating any resource (not only pods)\n",
    "from a YAML or JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RETRIEVING THE WHOLE DEFINITION OF A RUNNING POD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the pod, you can ask Kubernetes for the full YAML of the pod. You’ll\n",
    "see it’s similar to the YAML you saw earlier. You’ll learn about the additional fields\n",
    "appearing in the returned definition in the next sections. Go ahead and use the following\n",
    "command to see the full descriptor of the pod:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl get pod kubia-manual -o yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you’re more into JSON, you can also tell kubectl to return JSON instead of YAML\n",
    "like this (this works even if you used YAML to create the pod):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl get po kubia-manual -o json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SEEING YOUR NEWLY CREATED POD IN THE LIST OF PODS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your pod has been created, but how do you know if it’s running? Let’s list pods to see\n",
    "their statuses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s your kubia-manual pod. Its status shows that it’s running. If you’re like me,\n",
    "you’ll probably want to confirm that’s true by talking to the pod. You’ll do that in a\n",
    "minute. First, you’ll look at the app’s log to check for any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing application logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your little Node.js application logs to the process’s standard output. Containerized\n",
    "applications usually log to the standard output and standard error stream instead of\n",
    "writing their logs to files. This is to allow users to view logs of different applications in\n",
    "a simple, standard way.\n",
    "\n",
    "The container runtime (Docker in your case) redirects those streams to files and\n",
    "allows you to get the container’s log by running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    docker logs <container id>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could use ssh to log into the node where your pod is running and retrieve its logs\n",
    "with docker logs, but Kubernetes provides an easier way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RETRIEVING A POD’S LOG WITH KUBECTL LOGS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see your pod’s log (more precisely, the container’s log) you run the following command\n",
    "on your local machine (no need to ssh anywhere):\n",
    "    \n",
    "    kubectl logs kubia-manual\n",
    "\n",
    "You haven’t sent any web requests to your Node.js app, so the log only shows a single\n",
    "log statement about the server starting up. As you can see, retrieving logs of an application\n",
    "running in Kubernetes is incredibly simple if the pod only contains a single\n",
    "container.\n",
    "\n",
    "> NOTE: Container logs are automatically rotated daily and every time the log file\n",
    "reaches 10MB in size. The kubectl logs command only shows the log entries\n",
    "from the last rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPECIFYING THE CONTAINER NAME WHEN GETTING LOGS OF A MULTI-CONTAINER POD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your pod includes multiple containers, you have to explicitly specify the container\n",
    "name by including the -c <container name> option when running kubectl logs. In\n",
    "your kubia-manual pod, you set the container’s name to kubia, so if additional containers\n",
    "exist in the pod, you’d have to get its logs like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl logs kubia-manual -c kubia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can only retrieve container logs of pods that are still in existence. When\n",
    "a pod is deleted, its logs are also deleted. To make a pod’s logs available even after the\n",
    "pod is deleted, you need to set up centralized, cluster-wide logging, which stores all\n",
    "the logs into a central store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending requests to the pod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pod is now running—at least that’s what kubectl get and your app’s log say. But\n",
    "how do you see it in action? In the previous chapter, you used the kubectl expose\n",
    "command to create a service to gain access to the pod externally. You’re not going to\n",
    "do that now, because a whole chapter is dedicated to services, and you have other ways\n",
    "of connecting to a pod for testing and debugging purposes. One of them is through\n",
    "port forwarding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FORWARDING A LOCAL NETWORK PORT TO A PORT IN THE POD**\n",
    "\n",
    "When you want to talk to a specific pod without going through a service (for debugging\n",
    "or other reasons), Kubernetes allows you to configure port forwarding to the\n",
    "pod. This is done through the kubectl port-forward command. The following\n",
    "command will forward your machine’s local port 7000 to port 8080 of your kubiamanual\n",
    "pod:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    kubectl port-forward kubia-manual 7000:8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The port forwarder is running and you can now connect to your pod through the\n",
    "local port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONNECTING TO THE POD THROUGH THE PORT FORWARDER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a different terminal, you can now use curl to send an HTTP request to your pod\n",
    "through the kubectl port-forward proxy running on localhost:8888:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    curl localhost:7000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3.5 shows an overly simplified view of what happens when you send the request.\n",
    "In reality, a couple of additional components sit between the kubectl process and the\n",
    "pod, but they aren’t relevant right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using port forwarding like this is an effective way to test an individual pod."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing pods with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
